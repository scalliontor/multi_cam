# stereo_calibrate_live.py
# N√¢ng c·∫•p t·ª´ calculate_extrinsics.py ƒë·ªÉ s·ª≠ d·ª•ng cv2.stereoCalibrate cho k·∫øt qu·∫£ ch√≠nh x√°c h∆°n.

import pyrealsense2 as rs
import numpy as np
import cv2
import os

# --- 1. C·∫§U H√åNH ---
# ƒê·ªïi t√™n bi·∫øn ƒë·ªÉ r√µ r√†ng h∆°n: "tr√°i" v√† "ph·∫£i" thay v√¨ "point cloud" v√† "rgb"
LEFT_CAMERA_SN = "832112070255"
RIGHT_CAMERA_SN = "213622078112"      

CONFIG_FILE = "charuco_board_config.npz"
INTRINSICS_LEFT_FILE = f"intrinsics_charuco_{LEFT_CAMERA_SN}.npz"
INTRINSICS_RIGHT_FILE = f"intrinsics_charuco_{RIGHT_CAMERA_SN}.npz"
OUTPUT_FILE = "stereo_calibration.npz"

# Ki·ªÉm tra c√°c file c·∫ßn thi·∫øt
for f in [CONFIG_FILE, INTRINSICS_LEFT_FILE, INTRINSICS_RIGHT_FILE]:
    if not os.path.exists(f):
        print(f"L·ªói: Thi·∫øu file b·∫Øt bu·ªôc: '{f}'")
        exit()

# T·∫£i c·∫•u h√¨nh b·∫£ng ChArUco
config_data = np.load(CONFIG_FILE)
board = cv2.aruco.CharucoBoard(
    (int(config_data['squares_x']), int(config_data['squares_y'])),
    float(config_data['square_size_mm']),
    float(config_data['marker_size_mm']),
    cv2.aruco.getPredefinedDictionary(int(config_data['aruco_dict_id']))
)
detector = cv2.aruco.CharucoDetector(board)

# T·∫£i th√¥ng s·ªë n·ªôi t·∫°i ban ƒë·∫ßu (s·∫Ω ƒë∆∞·ª£c tinh ch·ªânh l·∫°i)
with np.load(INTRINSICS_LEFT_FILE) as data:
    mtx_left_initial = data['mtx']
    dist_left_initial = data['dist']

with np.load(INTRINSICS_RIGHT_FILE) as data:
    mtx_right_initial = data['mtx']
    dist_right_initial = data['dist']


# --- 2. THI·∫æT L·∫¨P REALSENSE PIPELINES (CH·ªà C·∫¶N LU·ªíNG M√ÄU) ---
pipeline_left = rs.pipeline()
config_left = rs.config()
config_left.enable_device(LEFT_CAMERA_SN)
config_left.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)

pipeline_right = rs.pipeline()
config_right = rs.config()
config_right.enable_device(RIGHT_CAMERA_SN)
config_right.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)

# B·∫Øt ƒë·∫ßu streaming
pipeline_left.start(config_left)
pipeline_right.start(config_right)

# --- 3. THU TH·∫¨P D·ªÆ LI·ªÜU ---
# C√°c list ƒë·ªÉ l∆∞u tr·ªØ ƒëi·ªÉm t·ª´ t·∫•t c·∫£ c√°c l·∫ßn ch·ª•p h·ª£p l·ªá
all_obj_points = []   # T·ªça ƒë·ªô 3D c·ªßa c√°c g√≥c tr√™n b·∫£ng (h·ªá t·ªça ƒë·ªô c·ªßa b·∫£ng)
all_img_points_left = []  # T·ªça ƒë·ªô 2D c·ªßa c√°c g√≥c tr√™n ·∫£nh t·ª´ camera tr√°i
all_img_points_right = [] # T·ªça ƒë·ªô 2D c·ªßa c√°c g√≥c tr√™n ·∫£nh t·ª´ camera ph·∫£i

# L·∫•y t·ªça ƒë·ªô 3D l√Ω t∆∞·ªüng c·ªßa t·∫•t c·∫£ c√°c g√≥c tr√™n b·∫£ng m·ªôt l·∫ßn duy nh·∫•t
all_board_corners_3d = board.getChessboardCorners()

print("Di chuy·ªÉn b·∫£ng ChArUco ƒë·∫øn nhi·ªÅu v·ªã tr√≠ v√† g√≥c ƒë·ªô kh√°c nhau.")
print("Nh·∫•n 'c' ƒë·ªÉ ch·ª•p m·ªôt c·∫∑p ·∫£nh. C·∫ßn √≠t nh·∫•t 15-20 c·∫∑p ·∫£nh t·ªët.")
print("Nh·∫•n 'q' ƒë·ªÉ k·∫øt th√∫c v√† b·∫Øt ƒë·∫ßu hi·ªáu ch·ªânh.")

try:
    while True:
        frames_left = pipeline_left.wait_for_frames()
        frames_right = pipeline_right.wait_for_frames()
        
        color_frame_left = frames_left.get_color_frame()
        color_frame_right = frames_right.get_color_frame()

        if not color_frame_left or not color_frame_right:
            continue

        img_left = np.asanyarray(color_frame_left.get_data())
        img_right = np.asanyarray(color_frame_right.get_data())
        
        gray_left = cv2.cvtColor(img_left, cv2.COLOR_BGR2GRAY)
        gray_right = cv2.cvtColor(img_right, cv2.COLOR_BGR2GRAY)

        corners_left, ids_left, _, _ = detector.detectBoard(gray_left)
        corners_right, ids_right, _, _ = detector.detectBoard(gray_right)

        if ids_left is not None: cv2.aruco.drawDetectedCornersCharuco(img_left, corners_left, ids_left)
        if ids_right is not None: cv2.aruco.drawDetectedCornersCharuco(img_right, corners_right, ids_right)
        
        cv2.putText(img_left, f"Captured: {len(all_obj_points)}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        cv2.imshow('Left Camera', img_left)
        cv2.imshow('Right Camera', img_right)

        key = cv2.waitKey(1)
        if key == ord('q'):
            break
        
        if key == ord('c') and ids_left is not None and ids_right is not None:
            print(f"Attempting to capture frame #{len(all_obj_points) + 1}...")

            # --- LOGIC THU TH·∫¨P ƒêI·ªÇM ƒê√É S·ª¨A ƒê·ªîI CHO STEREO ---
            # T√¨m c√°c ID g√≥c chung m√† c·∫£ hai camera ƒë·ªÅu nh√¨n th·∫•y
            common_ids = np.intersect1d(ids_left.flatten(), ids_right.flatten())
            
            if len(common_ids) > 6: # C·∫ßn √≠t nh·∫•t 6 g√≥c chung ƒë·ªÉ ƒë·∫£m b·∫£o ch·∫•t l∆∞·ª£ng
                objp_frame = []
                imgp_left_frame = []
                imgp_right_frame = []

                # Ch·ªâ l·∫∑p qua c√°c ID chung
                for id_val in common_ids:
                    # L·∫•y t·ªça ƒë·ªô 3D l√Ω t∆∞·ªüng c·ªßa g√≥c t·ª´ ƒë·ªãnh nghƒ©a c·ªßa b·∫£ng
                    objp_frame.append(all_board_corners_3d[id_val])
                    
                    # L·∫•y t·ªça ƒë·ªô 2D t∆∞∆°ng ·ª©ng t·ª´ m·ªói camera
                    idx_left = np.where(ids_left.flatten() == id_val)[0][0]
                    imgp_left_frame.append(corners_left[idx_left])
                    
                    idx_right = np.where(ids_right.flatten() == id_val)[0][0]
                    imgp_right_frame.append(corners_right[idx_right])

                # Th√™m c√°c c·∫∑p ƒëi·ªÉm ƒë√£ ƒë∆∞·ª£c kh·ªõp ho√†n h·∫£o v√†o danh s√°ch t·ªïng
                all_obj_points.append(np.array(objp_frame, dtype=np.float32))
                all_img_points_left.append(np.array(imgp_left_frame, dtype=np.float32))
                all_img_points_right.append(np.array(imgp_right_frame, dtype=np.float32))
                
                print(f"Capture successful with {len(common_ids)} common corners.")
            else:
                print("Capture failed: Not enough common corners found. Reposition the board.")

finally:
    pipeline_left.stop()
    pipeline_right.stop()
    cv2.destroyAllWindows()

# --- 4. TH·ª∞C HI·ªÜN HI·ªÜU CH·ªàNH STEREO ---
if len(all_obj_points) < 15:
    print(f"\nC·∫¢NH B√ÅO: Ch·ªâ c√≥ {len(all_obj_points)} c·∫∑p ·∫£nh ƒë∆∞·ª£c ch·ª•p. K·∫øt qu·∫£ hi·ªáu ch·ªânh c√≥ th·ªÉ kh√¥ng t·ªët.")
    if len(all_obj_points) < 5:
        print("Kh√¥ng ƒë·ªß d·ªØ li·ªáu. Tho√°t.")
        exit()

print(f"\n=== B·∫ÆT ƒê·∫¶U HI·ªÜU CH·ªàNH STEREO V·ªöI {len(all_obj_points)} C·∫∂P ·∫¢NH ===")
image_size = gray_left.shape[::-1] # (width, height)

# S·ª≠ d·ª•ng c·ªù CALIB_USE_INTRINSIC_GUESS ƒë·ªÉ cho ph√©p thu·∫≠t to√°n tinh ch·ªânh th√™m c√°c th√¥ng s·ªë n·ªôi t·∫°i
flags = cv2.CALIB_USE_INTRINSIC_GUESS

ret, mtx_left, dist_left, mtx_right, dist_right, R, T, E, F = cv2.stereoCalibrate(
    all_obj_points,
    all_img_points_left,
    all_img_points_right,
    mtx_left_initial,
    dist_left_initial,
    mtx_right_initial,
    dist_right_initial,
    image_size,
    flags=flags,
    criteria=(cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)
)

if ret:
    print("\n" + "="*50)
    print("üéâ HI·ªÜU CH·ªàNH STEREO TH√ÄNH C√îNG!")
    print("="*50)

    print(f"\nCh·∫•t l∆∞·ª£ng hi·ªáu ch·ªânh:")
    print(f"üìä L·ªói chi·∫øu l·∫°i trung b√¨nh (Reprojection Error): {ret:.4f} pixels")
    if ret < 1.0: print("‚úÖ Ch·∫•t l∆∞·ª£ng hi·ªáu ch·ªânh t·ªët.")
    else: print("‚ö†Ô∏è Ch·∫•t l∆∞·ª£ng hi·ªáu ch·ªânh t·ªá.")
    
    # L∆∞u k·∫øt qu·∫£
    np.savez(OUTPUT_FILE,
             mtx_left=mtx_left, dist_left=dist_left,
             mtx_right=mtx_right, dist_right=dist_right,
             R=R, T=T, E=E, F=F,
             reprojection_error=ret, image_size=image_size
             )
    
    print(f"\nüíæ K·∫øt qu·∫£ ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o file: {OUTPUT_FILE}")
    print("\n--- TH√îNG S·ªê NGO·∫†I T·∫†I (Extrinsics) ---")
    print("(M·ªëi quan h·ªá c·ªßa Camera Ph·∫£i so v·ªõi Camera Tr√°i)")
    print("\nüîÑ Ma tr·∫≠n xoay (Rotation Matrix R):")
    print(R)
    print("\nüìè Vector t·ªãnh ti·∫øn (Translation Vector T) theo mm:")
    print(T)
else:
    print("\n‚ùå Hi·ªáu ch·ªânh Stereo th·∫•t b·∫°i. H√£y th·ª≠ l·∫°i v·ªõi nhi·ªÅu ·∫£nh ƒëa d·∫°ng h∆°n.")